{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this tutorial uses Intel Optimized Caffe, the same general techniques apply to other frameworks like MXNet, Neon, Theano, Torch, TensorFlow, etc. [Caffe](http://caffe.berkeleyvision.org/) is a deep learning framework written in C++ and CUDA C++ developed by the Berkeley Vision and Learning Center ([BVLC](http://caffe.berkeleyvision.org/)). Intel Optimized Caffe is kept in synched with Caffe and therefore has all the benefits of Caffe. In addition, Intel Optimized Caffe is integrated with the latest release of Intel® Math Kernel Library (Intel® MKL) 2017 optimized for deep learning primitives on EC2 CPU instances. In addition Intel Optimized Caffe can be used for distributed multinode training or fine-tuning across various nodes. A tutorial for AWS distributed training can be found [here](https://software.intel.com/en-us/articles/distributed-training-of-deep-networks-on-amazon-web-services-aws).\n",
    "\n",
    "In this tutorial we go through the steps of installing Intel Optimized Caffe and BVLC Caffe, comparing performance on Intel Optimized Caffe vs BVLC Caffe, and fine-tuning a model. I'll explain what is fine-tuning below. A detailed explanation of installing and using Intel Optimized Caffe can be found [here](https://software.intel.com/en-us/articles/training-and-deploying-deep-learning-networks-with-caffe-optimized-for-intel-architecture).\n",
    "\n",
    "This tutorial has been tested using Ubuntu 14.04 and Ubuntu 16.04 on c4.8xlarge EC2 instances. I strongly suspect that it works on most instances with memory > 3 GB. Prior to these steps, start an Ubuntu 16.04 AMI using c4.8xlarge instance.\n",
    "\n",
    "To run this notebook:\n",
    "\n",
    "- Start a brand new Ubuntu 16.04 instance on a c4.8xlarge\n",
    "- Download this jupyter notebook `wget INSERT`\n",
    "- Download or scp the Dogs Vs Cats dataset (instructions below)\n",
    "- Download Install [Anaconda](https://www.continuum.io/downloads)\n",
    "- Run `jupyter notebook`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# get dependencies\n",
    "sudo apt-get update &&\n",
    "sudo apt-get install -y git build-essential &&\n",
    "sudo apt-get install -y libprotobuf-dev libleveldb-dev libsnappy-dev &&\n",
    "sudo apt-get install -y libopencv-dev libhdf5-serial-dev protobuf-compiler &&\n",
    "sudo apt-get install -y --no-install-recommends libboost-all-dev &&\n",
    "sudo apt-get install -y libgflags-dev libgoogle-glog-dev liblmdb-dev &&\n",
    "sudo apt-get install -y libatlas-base-dev "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# not needed if using Ubuntu 14.04\n",
    "cd /usr/lib/x86_64-linux-gnu\n",
    "sudo ln -s libhdf5_serial.so.10.1.0 libhdf5.so\n",
    "sudo ln -s libhdf5_serial_hl.so.10.0.2 libhdf5_hl.so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# download Intel Optimized Caffe and BVLC Caffe\n",
    "cd ~\n",
    "git clone https://github.com/intel/caffe.git \n",
    "mv caffe caffe-intel\n",
    "cd caffe-intel\n",
    "sed -i -e 's/# CPU_ONLY/CPU_ONLY/g' /tmp/file.txt\n",
    "echo 'INCLUDE_DIRS += /usr/include/hdf5/serial/' >> Makefile.config\n",
    "cd ~\n",
    "git clone https://github.com/BVLC/caffe.git\n",
    "mv caffe caffe-bvlc\n",
    "cd caffe-bvlc\n",
    "cp Makefile.config.example Makefile.config\n",
    "sed -i -e 's/# CPU_ONLY/CPU_ONLY/g' /tmp/file.txt\n",
    "echo 'INCLUDE_DIRS += /usr/include/hdf5/serial/' >> Makefile.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'bash'\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# compile\n",
    "# get the number of threads in order to use all threads to compile\n",
    "NUM_THREADS=$(($(grep 'core id' /proc/cpuinfo | sort -u | wc -l)*2))\n",
    "\n",
    "cd ~/caffe-intel\n",
    "make -j NUM_THREADS # downloads MKL DL functions on 1st make\n",
    "\n",
    "cd ~/caffe-bvlc\n",
    "make -j NUM_THREADS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both BVLC Caffe and Intel Optimized Caffe are now installed and compiled. For a comparison of performance on CPUs we will ran CaffeNet for a few iterations. CaffeNet and AlexNet are equivalent except for switching the pooling and normalization layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# time the performance on BVLC Caffe on 10 iterations\n",
    "cd ~/caffe-bvlc\n",
    "build/tool/caffe time --model=/home/ubuntu/caffe-bvlc/models/bvlc_reference_caffenet/deploy.prototxt -iterations 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# time the performance on Intel Optimized Caffe on 100 iterations\n",
    "cd ~/caffe-intel\n",
    "build/tool/caffe time --model=/home/ubuntu/caffe-bvlc/models/bvlc_reference_caffenet/train.prototxt -iterations 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial we will use the data from the Kaggle dogs vs cats competition to fine-tune a model. In order to use the data you need to login to the Kaggle website and download the data, or login and then copy the cookies and download the data as follows:\n",
    "\n",
    "~~~ bash\n",
    "cd ~\n",
    "mkdir dogvscat\n",
    "wget -x --load-cookies cookies.txt -P dogvscat -nH --cut-dirs=5 http://www.kaggle.com/c/dogs-vs-cats/download/train.zip\n",
    "~~~\n",
    "\n",
    "In the reminder of this tutorial, we assume that the data has been downloaded and is already in the dogvscat folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# unzip the training data\n",
    "sudo apt-get -y install unzip\n",
    "cd ~/dogvscat\n",
    "unzip train.zip -d ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'train'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-aa532485496b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mfv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mVAL_TEXT_FILE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mfilenames\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mIMAGE_FOLDER\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'cat'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'train'"
     ]
    }
   ],
   "source": [
    "# Selects 10% of the images (the ones that end in '2') for validation\n",
    "# Prepares train.txt and val.txt with the names and labels of the images\n",
    "import sys\n",
    "import os\n",
    "import os.path\n",
    "\n",
    "TRAIN_TEXT_FILE = 'train.txt'\n",
    "VAL_TEXT_FILE = 'val.txt'\n",
    "IMAGE_FOLDER = 'train'\n",
    "\n",
    "fr = open(TRAIN_TEXT_FILE, 'w')\n",
    "fv = open(VAL_TEXT_FILE, 'w')\n",
    "\n",
    "filenames = os.listdir(IMAGE_FOLDER)\n",
    "for filename in filenames:\n",
    "  if filename[0:3] == 'cat':\n",
    "    if filename[-5] == '2':# or filename[-5] == '8':\n",
    "      fv.write(filename + ' 0\\n')\n",
    "    else:\n",
    "      fr.write(filename + ' 0\\n')\n",
    "  if filename[0:3] == 'dog':\n",
    "    if filename[-5] == '2':# or filename[-5] == '8':\n",
    "      fv.write(filename + ' 1\\n')\n",
    "    else:\n",
    "      fr.write(filename + ' 1\\n')\n",
    "\n",
    "    fr.close()\n",
    "fv.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# convert to dataset to lmdb format\n",
    "# training set\n",
    "/home/ubuntu/caffe-intel/build/tools/convert_imageset \\\n",
    "  --resize_height=256 \\\n",
    "  --resize_width=256 \\\n",
    "  --shuffle \\\n",
    "  /home/ubuntu/dogvscat/train/ \\\n",
    "  /home/ubuntu/dogvscat/train.txt \\\n",
    "  /home/ubuntu/dogvscat/train_lmdb\n",
    "# validation set\n",
    "/home/ubuntu/caffe-intel/build/tools/convert_imageset \\\n",
    "  --resize_height=256 \\\n",
    "  --resize_width=256 \\\n",
    "  --shuffle \\\n",
    "  /home/ubuntu/dogvscat/train/ \\\n",
    "  /home/ubuntu/dogvscat/val.txt \\\n",
    "  /home/ubuntu/dogvscat/val_lmdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Download CaffeNet weights trained on ImageNet\n",
    "$CAFFE_ROOT/scripts/download_model_binary.py $CAFFE_ROOT/models/bvlc_reference_caffenet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recyle the layer definition prototxt file and made the following two changes:\n",
    "\n",
    "1. Change the data layer to include the new data:\n",
    "\n",
    "~~~ bash\n",
    "layer {\n",
    "  name: \"data\"\n",
    "  type: \"Data\"\n",
    "  data_param {\n",
    "    source: \"trained_lmdb\" # CHANGED LINE\n",
    "    ...\n",
    "    }\n",
    "  ...\n",
    "  }\n",
    "}\n",
    "~~~\n",
    "\n",
    "2. Change the last layer, e.g., \"fc8\" (note: in testing, make this same change to the deploy.prototxt file):\n",
    "\n",
    "~~~ bash\n",
    "layer {\n",
    "  name: \"ip8-ft\" # CHANGED LINE\n",
    "  type: \"InnerProduct\"\n",
    "  inner_product_param {\n",
    "    num_output: 2 # CHANGED LINE\n",
    "    ...\n",
    "    }\n",
    "  ...\n",
    "  }\n",
    "}\n",
    "~~~\n",
    "\n",
    "<h4>Fine-tuning guidelines</h4>\n",
    "- Learn the last layer first (earlier layer weights won't change very much in fine-tuning)\n",
    "  - Caffe layers have local learning rates: `lr_mult`\n",
    "  - Freeze all but the last layer for fast optimization, i.e., `lr_mult=0`\n",
    "  - Stop if good enough or keep fine-tuning other layers\n",
    "  - This will speed up training times\n",
    "- Alternatively you could leave all learning rates as they are and increase the last two layers\n",
    "  - Last layer by 10x\n",
    "  - Second to last by 5x\n",
    "- Reduce the learning rate\n",
    "  - Drop the initial learning rate (in the solver_file.prototxt) by 10x or 100x\n",
    "\n",
    "<h4>What happens under the hood</h4>\n",
    "- Creates a new network\n",
    "- Copy the previous weights to initialized network weights\n",
    "- Solves the usual way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# get train_val.prototxt modified for fine-tuning\n",
    "cd ~/dogvscat\n",
    "wget finetune.prototxt\n",
    "diff finetune.prototxt \\\n",
    "~/caffe-bvlc/models/bvlc_reference_caffenet/train_val.prototxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# get solver.prototxt modified for fine-tuning\n",
    "wget solver.prototxt\n",
    "diff solver.prototxt \\\n",
    "~/caffe-bvlc/models/bvlc_reference_caffenet/solver.prototxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# edit the solver.prototxt file and finetune network w/a larger learning rate\n",
    "sed -i -e 's/test_interval.*/test_interval: 1/g' solver.prototxt\n",
    "sed -i -e 's/base_lr.*/base_lr: 0.003/g' solver.prototxt\n",
    "sed -i -e 's/max_iter.*/max_iter: 50/g' solver.prototxt\n",
    "/home/ubuntu/caffe-intel/build/tools/caffe train -solver solver.prototxt -weights \\\n",
    "/home/ubuntu/caffe-intel/models/bvlc_reference_caffenet/weights.caffenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# edit the solver.prototxt file and finetune network w/a small learning rate\n",
    "sed -i -e 's/test_interval.*/test_interval: 1/g' solver.prototxt\n",
    "sed -i -e 's/base_lr.*/base_lr: 0.00001/g' solver.prototxt\n",
    "sed -i -e 's/max_iter.*/max_iter: 50/g' solver.prototxt\n",
    "/home/ubuntu/caffe-intel/build/tools/caffe train -solver solver.prototxt -weights \\\n",
    "/home/ubuntu/caffe-intel/models/bvlc_reference_caffenet/weights.caffenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# edit the solver.prototxt file and finetune network w/a good learning rate\n",
    "sed -i -e 's/test_interval.*/test_interval: 100/g' solver.prototxt\n",
    "sed -i -e 's/base_lr.*/base_lr: 0.001/g' solver.prototxt\n",
    "sed -i -e 's/max_iter.*/max_iter: 500/g' solver.prototxt\n",
    "/home/ubuntu/caffe-intel/build/tools/caffe train -solver solver.prototxt -weights \\\n",
    "/home/ubuntu/caffe-intel/models/bvlc_reference_caffenet/weights.caffenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Prepare to use Python to classify images\n",
    "import caffe\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "blob = caffe.proto.caffe_pb2.BlobProto()\n",
    "data = open( 'dogvscat_mean.binaryproto' , 'rb' ).read()\n",
    "blob.ParseFromString(data)\n",
    "arr = np.array( caffe.io.blobproto_to_array(blob) )\n",
    "out = arr[0]\n",
    "np.save( 'dogvscat_mean.npy' , out )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load trained network\n",
    "import numpy as np\n",
    "import sys\n",
    "import caffe\n",
    "import Image\n",
    "\n",
    "MODEL_FILE = '/home/ubuntu/dogvscat/deploy.prototxt' # architecture\n",
    "PRETRAINED = '/home/ubuntu/dogvscat/dogvscat_iter_500.caffemodel' # weights\n",
    "\n",
    "# Make sure that caffe is on the python path:\n",
    "sys.path.insert(0, '/home/ubuntu/caffe-intel/python')\n",
    "\n",
    "# Note arguments to preprocess input\n",
    "#  mean subtraction switched on by giving a mean array\n",
    "#  input channel swapping takes care of mapping RGB into BGR (CAFFE uses OpenCV which reads it as BGR)\n",
    "#  raw scaling (max value in the images in order to scale the CNN input to [0 1])\n",
    "caffe.set_mode_cpu()\n",
    "net = caffe.Classifier(MODEL_FILE, PRETRAINED,\n",
    "                       mean=np.load('/home/ubuntu/dogvscat/dogvscat_mean.npy').mean(1).mean(1),\n",
    "                       channel_swap=(2,1,0),\n",
    "                       raw_scale=255,\n",
    "                       image_dims=(256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# classify an image\n",
    "imfile = '/home/ubuntu/dogvscat/train/cat.2.jpg'\n",
    "image = Image.open(imfile)\n",
    "image.show()\n",
    "im = caffe.io.load.image(imfile)\n",
    "prediction = net.predict(im, 'false')\n",
    "if prediction.argmax() = 0:\n",
    "    print 'cat'\n",
    "else:\n",
    "    print 'dog'"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
