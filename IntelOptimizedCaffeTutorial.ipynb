{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this tutorial uses Intel Optimized Caffe, the same general techniques apply to other frameworks like MXNet, Neon, Theano, Torch, TensorFlow, etc. [Caffe](http://caffe.berkeleyvision.org/) is a deep learning framework written in C++ and CUDA C++ developed by the Berkeley Vision and Learning Center ([BVLC](http://caffe.berkeleyvision.org/)). Intel Optimized Caffe is kept in synched with Caffe and therefore has all the benefits of Caffe. In addition, Intel Optimized Caffe is integrated with the latest release of Intel® Math Kernel Library (Intel® MKL) 2017 optimized for deep learning primitives on EC2 CPU instances. In addition Intel Optimized Caffe can be used for distributed multinode training or fine-tuning across various nodes. A tutorial for AWS distributed training can be found [here](https://software.intel.com/en-us/articles/distributed-training-of-deep-networks-on-amazon-web-services-aws).\n",
    "\n",
    "In this tutorial we go through the steps of installing Intel Optimized Caffe and BVLC Caffe, comparing performance on Intel Optimized Caffe vs BVLC Caffe, and fine-tuning a model. I'll explain what is fine-tuning below. A detailed explanation of installing and using Intel Optimized Caffe can be found [here](https://software.intel.com/en-us/articles/training-and-deploying-deep-learning-networks-with-caffe-optimized-for-intel-architecture).\n",
    "\n",
    "This tutorial has been tested using Ubuntu 14.04 and Ubuntu 16.04 on c4.8xlarge EC2 instances. I strongly suspect that it works on most instances with memory > 3 GB. Prior to these steps, start an Ubuntu 16.04 AMI using c4.8xlarge instance.\n",
    "\n",
    "To run this notebook:\n",
    "\n",
    "- Start a brand new Ubuntu 16.04 instance on a c4.8xlarge\n",
    "- Update: `sudo apt-get update`\n",
    "- Download this jupyter notebook: `wget https://raw.githubusercontent.com/RodriguezAndres/CaffeTutorial/master/IntelOptimizedCaffeTutorial.ipynb -O IntelOptimizedCaffeTutorial.ipynb`\n",
    "- Download or scp the Dogs Vs Cats dataset (instructions below)\n",
    "- Download Install [Anaconda](https://www.continuum.io/downloads) and setup jupyter:\n",
    "  - `wget https://repo.continuum.io/archive/Anaconda2-4.2.0-Linux-x86_64.sh`\n",
    "  - `bash Anaconda2-4.2.0-Linux-x86_64.sh`\n",
    "  - `source .bashrc`\n",
    "  - `wget https://raw.githubusercontent.com/RodriguezAndres/CaffeTutorial/master/jupyter_setup.sh`\n",
    "  - `chmod +x jupyter_setup.sh`\n",
    "  - `./jupyter_setup.sh`\n",
    "- Run: `jupyter notebook`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# get dependencies\n",
    "sudo apt-get update &&\n",
    "sudo apt-get install -y git build-essential &&\n",
    "sudo apt-get install -y libprotobuf-dev libleveldb-dev libsnappy-dev &&\n",
    "sudo apt-get install -y libopencv-dev libhdf5-serial-dev protobuf-compiler &&\n",
    "sudo apt-get install -y --no-install-recommends libboost-all-dev &&\n",
    "sudo apt-get install -y libgflags-dev libgoogle-glog-dev liblmdb-dev &&\n",
    "sudo apt-get install -y libatlas-base-dev "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# not needed if using Ubuntu 14.04\n",
    "cd /usr/lib/x86_64-linux-gnu\n",
    "sudo ln -s libhdf5_serial.so.10.1.0 libhdf5.so\n",
    "sudo ln -s libhdf5_serial_hl.so.10.0.2 libhdf5_hl.so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# download Intel Optimized Caffe and BVLC Caffe\n",
    "cd ~\n",
    "git clone https://github.com/intel/caffe.git \n",
    "mv caffe caffe-intel\n",
    "cd caffe-intel\n",
    "cp Makefile.config.example Makefile.config\n",
    "# modify Makefile to run on CPU and use Anaconda\n",
    "sed -i -e 's/# CPU_ONLY/CPU_ONLY/g' Makefile.config\n",
    "sed -i -e 's/PYTHON_INCLUDE := \\/usr\\/include\\/python2.7/# PYTHON_INCLUDE := \\/usr\\/include\\/python2.7/g' Makefile.config\n",
    "sed -i -e 's/\\/usr\\/lib\\/python2.7\\/dist-packages\\/numpy\\/core\\/include/# \\/usr\\/lib\\/python2.7\\/dist-packages\\/numpy\\/core\\/include/g' Makefile.config\n",
    "sed -i -e 's/# ANACONDA_HOME := $(HOME)\\/anaconda/ANACONDA_HOME := \\/home\\/ubuntu\\/anaconda2/g' Makefile.config\n",
    "sed -i -e 's/# PYTHON_INCLUDE := $(ANACONDA_HOME)/PYTHON_INCLUDE := $(ANACONDA_HOME)/g' Makefile.config\n",
    "sed -i -e 's/# $(ANACONDA_HOME)/$(ANACONDA_HOME)/g' Makefile.config\n",
    "sed -i -e 's/PYTHON_LIB := \\/usr\\/lib/# PYTHON_LIB := \\/usr\\/lib/g' Makefile.config\n",
    "sed -i -e 's/# PYTHON_LIB := $(ANACONDA_HOME)/PYTHON_LIB := $(ANACONDA_HOME)/g' Makefile.config\n",
    "sed -i -e 's/INCLUDE_DIRS := $(PYTHON_INCLUDE) \\/usr\\/local\\/include/INCLUDE_DIRS := $(PYTHON_INCLUDE) \\/usr\\/local\\/include \\/usr\\/include\\/hdf5\\/serial\\//g' Makefile.config\n",
    "cd ~\n",
    "git clone https://github.com/BVLC/caffe.git\n",
    "mv caffe caffe-bvlc\n",
    "cd caffe-bvlc\n",
    "cp Makefile.config.example Makefile.config\n",
    "sed -i -e 's/# CPU_ONLY/CPU_ONLY/g' Makefile.config\n",
    "sed -i -e 's/INCLUDE_DIRS := $(PYTHON_INCLUDE) \\/usr\\/local\\/include/INCLUDE_DIRS := $(PYTHON_INCLUDE) \\/usr\\/local\\/include \\/usr\\/include\\/hdf5\\/serial\\//g' Makefile.config\n",
    "conda install libgcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# compile BVLC Caffe and Intel Caffe\n",
    "# get the number of threads in order to use all threads to compile\n",
    "NUMTHREADS=$(($(grep 'core id' /proc/cpuinfo | sort -u | wc -l)*2))\n",
    "cd ~/caffe-bvlc\n",
    "make -j $NUMTHREADS\n",
    "cd ~/caffe-intel\n",
    "make -j $NUMTHREADS # downloads MKL DL functions on 1st make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# compile Pycaffe\n",
    "cd ~/caffe-intel\n",
    "cd python\n",
    "pip install --upgrade pip\n",
    "for req in $(cat requirements.txt); do pip install $req; done\n",
    "cd ~/caffe-intel\n",
    "make pycaffe\n",
    "echo \"export PYTHONPATH=/home/ubuntu/caffe-intel/python\" >> ~/.bashrc\n",
    "echo 'export LD_LIBRARY_PATH=\"$LD_LIBRARY_PATH:/home/ubuntu/anaconda2/lib\"' >> ~/.bashrc\n",
    "source ~/.bashrc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both BVLC Caffe and Intel Optimized Caffe are now installed and compiled. For a comparison of performance on CPUs we will ran CaffeNet for a few iterations. CaffeNet and AlexNet are equivalent except for switching the pooling and normalization layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# time the performance on BVLC Caffe on 10 iterations\n",
    "cd ~/caffe-bvlc\n",
    "build/tools/caffe time --model=/home/ubuntu/caffe-bvlc/models/bvlc_reference_caffenet/deploy.prototxt -iterations 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# time the performance on Intel Optimized Caffe on 10 iterations\n",
    "cd ~/caffe-intel\n",
    "export LD_LIBRARY_PATH=\"$LD_LIBRARY_PATH:/home/ubuntu/anaconda2/lib\"\n",
    "build/tools/caffe time --model=/home/ubuntu/caffe-bvlc/models/bvlc_reference_caffenet/deploy.prototxt -iterations 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial we will use the data from the Kaggle dogs vs cats competition to fine-tune a model. In order to use the data you need to login to the Kaggle website and download the data, or login and then copy the cookies and download the data as follows:\n",
    "\n",
    "~~~ bash\n",
    "cd ~\n",
    "mkdir dogvscat\n",
    "wget -x --load-cookies cookies.txt -P dogvscat -nH --cut-dirs=5 http://www.kaggle.com/c/dogs-vs-cats/download/train.zip\n",
    "~~~\n",
    "\n",
    "In the reminder of this tutorial, we assume that the data has been downloaded and is already in the dogvscat folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# unzip the training data\n",
    "sudo apt-get -y install unzip\n",
    "cd /home/ubuntu/dogvscat\n",
    "unzip train.zip -d ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Selects 10% of the images (the ones that end in '2') for validation\n",
    "# Prepares train.txt and val.txt with the names and labels of the images\n",
    "%cd /home/ubuntu/dogvscat\n",
    "import sys\n",
    "import os\n",
    "import os.path\n",
    "\n",
    "TRAIN_TEXT_FILE = 'train.txt'\n",
    "VAL_TEXT_FILE = 'val.txt'\n",
    "IMAGE_FOLDER = 'train'\n",
    "\n",
    "fr = open(TRAIN_TEXT_FILE, 'w')\n",
    "fv = open(VAL_TEXT_FILE, 'w')\n",
    "\n",
    "filenames = os.listdir(IMAGE_FOLDER)\n",
    "for filename in filenames:\n",
    "  if filename[0:3] == 'cat':\n",
    "    if filename[-5] == '2':# or filename[-5] == '8':\n",
    "      fv.write(filename + ' 0\\n')\n",
    "    else:\n",
    "      fr.write(filename + ' 0\\n')\n",
    "  if filename[0:3] == 'dog':\n",
    "    if filename[-5] == '2':# or filename[-5] == '8':\n",
    "      fv.write(filename + ' 1\\n')\n",
    "    else:\n",
    "      fr.write(filename + ' 1\\n')\n",
    "\n",
    "fr.close()\n",
    "fv.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# convert to dataset to lmdb format\n",
    "# training set\n",
    "export LD_LIBRARY_PATH=\"$LD_LIBRARY_PATH:/home/ubuntu/anaconda2/lib\"\n",
    "/home/ubuntu/caffe-intel/build/tools/convert_imageset \\\n",
    "  --resize_height=256 \\\n",
    "  --resize_width=256 \\\n",
    "  --shuffle \\\n",
    "  /home/ubuntu/dogvscat/train/ \\\n",
    "  /home/ubuntu/dogvscat/train.txt \\\n",
    "  /home/ubuntu/dogvscat/train_lmdb\n",
    "# validation set\n",
    "/home/ubuntu/caffe-intel/build/tools/convert_imageset \\\n",
    "  --resize_height=256 \\\n",
    "  --resize_width=256 \\\n",
    "  --shuffle \\\n",
    "  /home/ubuntu/dogvscat/train/ \\\n",
    "  /home/ubuntu/dogvscat/val.txt \\\n",
    "  /home/ubuntu/dogvscat/val_lmdb\n",
    "  \n",
    "/home/ubuntu/caffe-intel/build/tools/compute_image_mean /home/ubuntu/dogvscat/train_lmdb \\\n",
    "  /home/ubuntu/dogvscat/dogvscat_mean.binaryproto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recyle the layer definition prototxt file and made the following two changes:\n",
    "\n",
    "1. Change the data layer to include the new data:\n",
    "\n",
    "~~~ bash\n",
    "layer {\n",
    "  name: \"data\"\n",
    "  type: \"Data\"\n",
    "  data_param {\n",
    "    source: \"trained_lmdb\" # CHANGED LINE\n",
    "    ...\n",
    "    }\n",
    "  ...\n",
    "  }\n",
    "}\n",
    "~~~\n",
    "\n",
    "2. Change the last layer, e.g., \"fc8\" (note: in testing, make this same change to the deploy.prototxt file):\n",
    "\n",
    "~~~ bash\n",
    "layer {\n",
    "  name: \"ip8-ft\" # CHANGED LINE\n",
    "  type: \"InnerProduct\"\n",
    "  inner_product_param {\n",
    "    num_output: 2 # CHANGED LINE\n",
    "    ...\n",
    "    }\n",
    "  ...\n",
    "  }\n",
    "}\n",
    "~~~\n",
    "\n",
    "<h4>Fine-tuning guidelines</h4>\n",
    "- Learn the last layer first (earlier layer weights won't change very much in fine-tuning)\n",
    "  - Caffe layers have local learning rates: `lr_mult`\n",
    "  - Freeze all but the last layer for fast optimization, i.e., `lr_mult=0`\n",
    "  - Stop if good enough or keep fine-tuning other layers\n",
    "  - This will speed up training times\n",
    "- Alternatively you could leave all learning rates as they are and increase the last two layers\n",
    "  - Last layer by 10x\n",
    "  - Second to last by 5x\n",
    "- Reduce the learning rate\n",
    "  - Drop the initial learning rate (in the solver_file.prototxt) by 10x or 100x\n",
    "\n",
    "<h4>What happens under the hood</h4>\n",
    "- Creates a new network\n",
    "- Copy the previous weights to initialized network weights\n",
    "- Solves the usual way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Download CaffeNet weights trained on ImageNet\n",
    "/home/ubuntu/caffe-intel/scripts/download_model_binary.py \\\n",
    "/home/ubuntu/caffe-intel/models/bvlc_reference_caffenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# get train_val.prototxt modified for fine-tuning\n",
    "cd ~/dogvscat\n",
    "wget https://raw.githubusercontent.com/RodriguezAndres/CaffeTutorial/master/finetuning.prototxt -O finetuning.prototxt\n",
    "diff finetuning.prototxt \\\n",
    "~/caffe-bvlc/models/bvlc_reference_caffenet/train_val.prototxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# get solver.prototxt modified for fine-tuning\n",
    "wget https://raw.githubusercontent.com/RodriguezAndres/CaffeTutorial/master/solver.prototxt -O solver.prototxt\n",
    "diff solver.prototxt \\\n",
    "~/caffe-bvlc/models/bvlc_reference_caffenet/solver.prototxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# get deploy.prototxt modified for fine-tuning\n",
    "wget https://raw.githubusercontent.com/RodriguezAndres/CaffeTutorial/master/deploy.prototxt -O deploy.prototxt\n",
    "diff deploy.prototxt \\\n",
    "~/caffe-bvlc/models/bvlc_reference_caffenet/deploy.prototxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# edit the solver.prototxt file and finetune network w/a larger learning rate\n",
    "cd ~/dogvscat\n",
    "sed -i -e 's/test_interval.*/test_interval: 1/g' solver.prototxt\n",
    "sed -i -e 's/base_lr.*/base_lr: 0.003/g' solver.prototxt\n",
    "sed -i -e 's/max_iter.*/max_iter: 10/g' solver.prototxt\n",
    "export LD_LIBRARY_PATH=\"$LD_LIBRARY_PATH:/home/ubuntu/anaconda2/lib\"\n",
    "/home/ubuntu/caffe-intel/build/tools/caffe train -solver solver.prototxt -weights \\\n",
    "/home/ubuntu/caffe-intel/models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# edit the solver.prototxt file and finetune network w/a small learning rate\n",
    "cd ~/dogvscat\n",
    "sed -i -e 's/test_interval.*/test_interval: 1/g' solver.prototxt\n",
    "sed -i -e 's/base_lr.*/base_lr: 0.000001/g' solver.prototxt\n",
    "sed -i -e 's/max_iter.*/max_iter: 15/g' solver.prototxt\n",
    "export LD_LIBRARY_PATH=\"$LD_LIBRARY_PATH:/home/ubuntu/anaconda2/lib\"\n",
    "/home/ubuntu/caffe-intel/build/tools/caffe train -solver solver.prototxt -weights \\\n",
    "/home/ubuntu/caffe-intel/models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# edit the solver.prototxt file and finetune network w/a good learning rate\n",
    "cd ~/dogvscat\n",
    "sed -i -e 's/test_interval.*/test_interval: 50/g' solver.prototxt\n",
    "sed -i -e 's/base_lr.*/base_lr: 0.001/g' solver.prototxt\n",
    "sed -i -e 's/max_iter.*/max_iter: 250/g' solver.prototxt\n",
    "export LD_LIBRARY_PATH=\"$LD_LIBRARY_PATH:/home/ubuntu/anaconda2/lib\"\n",
    "/home/ubuntu/caffe-intel/build/tools/caffe train -solver solver.prototxt -weights \\\n",
    "/home/ubuntu/caffe-intel/models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Prepare to use Python to classify images\n",
    "%cd /home/ubuntu/dogvscat\n",
    "import sys\n",
    "sys.path.insert(0, '/home/ubuntu/caffe-intel/python')\n",
    "import caffe\n",
    "import numpy as np\n",
    "\n",
    "blob = caffe.proto.caffe_pb2.BlobProto()\n",
    "data = open( 'dogvscat_mean.binaryproto' , 'rb' ).read()\n",
    "blob.ParseFromString(data)\n",
    "arr = np.array( caffe.io.blobproto_to_array(blob) )\n",
    "out = arr[0]\n",
    "np.save( 'dogvscat_mean.npy' , out )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load trained network\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.insert(0, '/home/ubuntu/caffe-intel/python')\n",
    "import caffe\n",
    "from IPython.display import Image\n",
    "\n",
    "MODEL_FILE = '/home/ubuntu/dogvscat/deploy.prototxt' # architecture\n",
    "PRETRAINED = '/home/ubuntu/dogvscat/dogvscat_iter_250.caffemodel' # weights\n",
    "\n",
    "# Make sure that caffe is on the python path:\n",
    "sys.path.insert(0, '/home/ubuntu/caffe-intel/python')\n",
    "\n",
    "# Note arguments to preprocess input\n",
    "#  mean subtraction switched on by giving a mean array\n",
    "#  input channel swapping takes care of mapping RGB into BGR (CAFFE uses OpenCV which reads it as BGR)\n",
    "#  raw scaling (max value in the images in order to scale the CNN input to [0 1])\n",
    "caffe.set_mode_cpu()\n",
    "net = caffe.Classifier(MODEL_FILE, PRETRAINED,\n",
    "                       mean=np.load('/home/ubuntu/dogvscat/dogvscat_mean.npy').mean(1).mean(1),\n",
    "                       channel_swap=(2,1,0),\n",
    "                       raw_scale=255,\n",
    "                       image_dims=(256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imfile = '/home/ubuntu/dogvscat/train/dog.10.jpg'\n",
    "Image(imfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# classify an image\n",
    "im = caffe.io.load_image(imfile)\n",
    "prediction = net.predict([im])\n",
    "if prediction[0].argmax() == 0:\n",
    "    print 'cat'\n",
    "else:\n",
    "    print 'dog'"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
